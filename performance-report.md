# Performance Test Results

**Test Date:** 2026-01-30
**Test Duration:** 3 minutes 30 seconds
**Instance Type:** AWS EC2 t2.micro (1 vCPU, 1GB RAM)

## Test Scenario

- Gradual ramp: 0 → 10 → 20 concurrent users
- Each user makes requests to homepage (/) and health endpoint (/health)
- 1 second pause between requests per user

## Results Summary

### Latency (Response Time)

| Percentile | Value |
|------------|-------|
| **Average** | 195.25ms |
| **Median (p50)** | 181.22ms |
| **p90** | 250.84ms |
| **p95** | 258.62ms |
| **Max** | 349.37ms |

### Throughput

- **Total Requests:** 2,270
- **Requests/second:** ~10.8 req/s
- **Total Iterations:** 1,135

### Reliability

- **Error Rate:** 0.00%
- **Success Rate:** 100%
- **All checks passed:** 3,405/3,405

## Threshold Results

| Threshold | Target | Actual | Status |
|-----------|--------|--------|--------|
| p95 Latency | <500ms | 258.62ms | ✅ PASS |
| Error Rate | <1% | 0.00% | ✅ PASS |

## Analysis

### What's Working Well

1. **Latency is excellent** — p95 at 258ms is well within acceptable range for web apps
2. **Zero errors** — Application handled all load without failures
3. **Stable under load** — Performance remained consistent even at 20 concurrent users
4. **Good throughput** — ~11 req/s on a t2.micro is reasonable

### Potential Bottlenecks

1. **Single t2.micro instance**
   - Limited to 1 vCPU, will saturate under heavier load
   - Current test shows headroom, but not much

2. **SQLite database**
   - Single-threaded, limited concurrency
   - Acceptable for MVP, not for scale

3. **No caching layer**
   - Every request hits the application
   - Static content could be cached

4. **Flask development server** (in debug mode)
   - Not optimized for production
   - Should use Gunicorn/uWSGI for production

## Recommendations

### Short-term (Current MVP)

Current capacity is sufficient for:
- ~100-200 daily active users
- ~10-20 concurrent users
- No immediate action required

### Medium-term (If Usage Grows)

1. **Upgrade instance**: t2.small (2 vCPU, 2GB) — ~$17/month
2. **Add production WSGI server**: Gunicorn with multiple workers
3. **Enable Flask caching**: Cache health endpoint and static responses

### Long-term (Scaling)

1. **Horizontal scaling**: Add load balancer + multiple instances
2. **Database migration**: SQLite → PostgreSQL RDS
3. **CDN**: CloudFront for static assets
4. **Auto-scaling**: Based on CPU metrics

## Capacity Planning

| Metric | Current Capacity | Target for Scale |
|--------|------------------|------------------|
| Concurrent Users | 20 | 100+ |
| Requests/sec | ~11 | ~50+ |
| p95 Latency | 258ms | <300ms |
| Instance Type | t2.micro | t2.small or larger |

## Conclusion

The application performs well within current requirements. The t2.micro free-tier instance handles 20 concurrent users with sub-300ms p95 latency and zero errors. No immediate optimization needed for MVP launch.

---

*Generated by k6 load testing tool*
